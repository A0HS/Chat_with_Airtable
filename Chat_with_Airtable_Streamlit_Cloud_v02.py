# ì‹¤í–‰ ìˆœì„œ
# í´ë” ì´ë™: cd "D:\Codes\my-projects\Dev-Chat_with_Airtable\Chat_with_Airtable_Streamlit_Cloud_v02"
# ê°€ìƒ í™˜ê²½ ìƒì„± (Windows): python -m venv venv
# íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install -r requirements.txt
# ìŠ¤íŠ¸ë¦¼ë¦¿ ì‹¤í–‰: streamlit run Chat_with_Airtable_Streamlit_Cloud_v2.py

import os
import json
import re
import traceback
import requests
import pandas as pd
import numpy as np
import openai
import streamlit as st

# âœ… ì„¤ì •
st.set_page_config(page_title="Chat with Airtable", page_icon="ğŸ¤–")
RECENT_TURNS_FOR_GPT = 3  # ìµœê·¼ ëŒ€í™” í„´ ìˆ˜ (GPT contextì— í¬í•¨)

# âœ… API í‚¤ ë¡œë”©
def read_api_key_from_file(file_path):
    try:
        with open(file_path, 'r') as file:
            return file.read().strip()
    except Exception as e:
        # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì‹œë„
        env_var = os.environ.get(file_path.replace(".txt", ""))
        if env_var:
            return env_var
        
        st.error(f"[íŒŒì¼ ì½ê¸° ì˜¤ë¥˜] {file_path} â†’ {e}")
        return None

# í™˜ê²½ ì„¤ì • - íŒŒì¼ì´ë‚˜ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
AIRTABLE_API_KEY = read_api_key_from_file("Airtable_Personal_access_token_BIGTURN.txt")
OPENAI_API_KEY = read_api_key_from_file("OpenAI_API_KEY.txt")
openai.api_key = OPENAI_API_KEY

# âœ… Airtable ë°ì´í„° ë¡œë”© í•¨ìˆ˜
def load_airtable_bases():
    """ëª¨ë“  Airtable ë² ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    url = "https://api.airtable.com/v0/meta/bases"
    headers = {"Authorization": f"Bearer {AIRTABLE_API_KEY}"}

    try:
        response = requests.get(url, headers=headers)
        return response.json().get("bases", [])
    except Exception as e:
        st.error(f"âŒ ë² ì´ìŠ¤ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_all_tables_in_base(base_id):
    """íŠ¹ì • ë² ì´ìŠ¤ì˜ ëª¨ë“  í…Œì´ë¸” ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    url = f"https://api.airtable.com/v0/meta/bases/{base_id}/tables"
    headers = {"Authorization": f"Bearer {AIRTABLE_API_KEY}"}

    try:
        response = requests.get(url, headers=headers)
        data = response.json()
        tables = data.get("tables", [])
        st.write(f"âœ… í…Œì´ë¸” {len(tables)}ê°œ ë¶ˆëŸ¬ì˜´")
        return [(t["name"], t["id"]) for t in tables]
    except Exception as e:
        st.error(f"âŒ í…Œì´ë¸” ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return []

@st.cache_data(ttl=3600)
def get_airtable_data(base_id, table_id):
    """íŠ¹ì • ë² ì´ìŠ¤ì˜ íŠ¹ì • í…Œì´ë¸” ë°ì´í„° ì „ì²´ ê°€ì ¸ì˜¤ê¸°"""
    url = f"https://api.airtable.com/v0/{base_id}/{table_id}"
    headers = {"Authorization": f"Bearer {AIRTABLE_API_KEY}"}
    all_records = []
    offset = None

    try:
        with st.spinner(f"í…Œì´ë¸” ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            while True:
                params = {"pageSize": 100}
                if offset:
                    params["offset"] = offset

                res = requests.get(url, headers=headers, params=params)
                data = res.json()

                # ì—ëŸ¬ ì‘ë‹µ ì‹œ ì¶œë ¥
                if 'error' in data:
                    st.error(f"âŒ ì—ëŸ¬ ë°œìƒ: {data['error']}")
                    break

                all_records.extend(data.get("records", []))
                offset = data.get("offset")
                if not offset:
                    break

        st.success(f"  âœ… ì´ {len(all_records)}ê°œ ë ˆì½”ë“œ ë¶ˆëŸ¬ì˜´")
        return all_records
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

# âœ… ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° ì •ë¦¬ í•¨ìˆ˜
def clean_column_name(col):
    """ì»¬ëŸ¼ëª… ì •ì œ: íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ìŠ¤ë„¤ì´í¬ ì¼€ì´ìŠ¤ë¡œ ë³€í™˜"""
    col = re.sub(r"[^\w\s]", "", col)
    col = col.strip().replace(" ", "_").lower()
    return col

def normalize_table_name(name):
    """í…Œì´ë¸”ëª… ì •ì œ: íŠ¹ìˆ˜ë¬¸ìë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ëŒ€ì²´"""
    return re.sub(r'\W+', '_', name.strip().lower())

def is_likely_date_column(series):
    """ë¬¸ìì—´ ì»¬ëŸ¼ ì¤‘ ë‚ ì§œ íŒ¨í„´ ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ True"""
    if not series.dtype == object:
        return False
    sample = series.dropna().astype(str).head(20)
    match_count = sum(bool(re.match(r"\d{4}[-/]\d{1,2}[-/]\d{1,2}", val)) for val in sample)
    return match_count >= max(3, len(sample) // 2)

def should_exclude_column(col_name):
    """ëª…ë°±íˆ ì‚¬ëŒì„ ì˜ë¯¸í•˜ëŠ” ì»¬ëŸ¼ë“¤ ì œì™¸"""
    exclude_keywords = ['_by', 'manager', 'agent', 'consultant', 'email']
    col_lower = col_name.lower()
    return any(kw in col_lower for kw in exclude_keywords)

# âœ… GPT ê´€ë ¨ ìœ í‹¸ í•¨ìˆ˜
def extract_code_blocks(response_text):
    """GPT ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡ë§Œ ì¶”ì¶œ"""
    match = re.search(r"```(?:python)?\s*([\s\S]+?)```", response_text)
    if not match:
        return response_text  # ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
    
    code = match.group(1).strip()
    return code

def execute_code(code_str, local_vars):
    """ì½”ë“œ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""
    if not isinstance(code_str, str):
        return {"success": False, "error": "ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: exec() ì¸ìëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."}
    try:
        exec(code_str, {}, local_vars)
        result = local_vars.get("result")
        return {"success": True, "result": result}
    except Exception as e:
        error_msg = traceback.format_exc()
        st.error(f"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        return {"success": False, "error": error_msg}

def ask_gpt(messages):
    """GPT API í˜¸ì¶œ"""
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=1500
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"GPT ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None

def sanitize_colon_spacing(text):
    """ë§ˆí¬ë‹¤ìš´ì—ì„œ 'ë¬¸ì¥:' í˜•ì‹ì„ ì˜ëª» ì¸ì‹í•˜ëŠ” ê²ƒì„ ë°©ì§€"""
    lines = text.split('\n')
    cleaned = []
    for line in lines:
        # ë§í¬ì¸ ê²½ìš° ì œì™¸ (http://, https:// ë“±)
        if "://" not in line:
            # ì½œë¡  ë’¤ì— ê³µë°±ì´ ì—†ëŠ” ê²½ìš° ì¶”ê°€
            line = re.sub(r"(\S):(\S)", r"\1: \2", line)
        cleaned.append(line)
    return "\n".join(cleaned)

# âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# âœ… ëŒ€í™” ë Œë”ë§ í•¨ìˆ˜
def render_chat_history():
    st.markdown("---")
    for msg in st.session_state.chat_history:            
        if msg.get("type") == "code":
            sanitized_code = msg["content"]
            # ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°í˜¸(#) ì´ìŠ¤ì¼€ì´í”„
            sanitized_code = re.sub(r"^(\s*)#{1,6}\s*", r"\1# ", sanitized_code, flags=re.MULTILINE)
            # HTML íƒœê·¸ ì´ìŠ¤ì¼€ì´í”„
            sanitized_code = sanitized_code.replace("<", "&lt;").replace(">", "&gt;")
            # ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
            sanitized_code = sanitized_code.replace("*", "\\*")
            sanitized_code = sanitized_code.replace("_", "\\_")
            sanitized_code = sanitized_code.replace("`", "\\`")

            # pre íƒœê·¸ ì‚¬ìš©ìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì™„ì „íˆ ë¬´íš¨í™”
            st.markdown(f"""
            <pre style='background-color: #e8e8e8; padding: 12px; border-radius: 8px; font-family: monospace; white-space: pre-wrap; margin: 10px 0;'>
{sanitized_code}
            </pre>
            """, unsafe_allow_html=True)

        elif msg["role"] == "user":
            st.markdown(f"""
<div style='text-align: right; background-color: #DCF8C6; padding: 10px; border-radius: 10px; margin: 5px 0; display: inline-block; float: right; clear: both;'>
{msg["content"]}
</div>
""", unsafe_allow_html=True)
        elif msg["role"] == "assistant":
            st.markdown(f"""
<div style='text-align: left; background-color: #F1F0F0; padding: 10px; border-radius: 10px; margin: 5px 0; display: inline-block; float: left; clear: both;'>
{msg["content"]}
</div>
""", unsafe_allow_html=True)
    st.markdown("<div style='clear: both;'></div>", unsafe_allow_html=True)

def get_recent_chat_messages(n=RECENT_TURNS_FOR_GPT):
    """ìµœê·¼ ní„´ì˜ ëŒ€í™” ë‚´ìš©ë§Œ ë°˜í™˜"""
    recent = st.session_state.chat_history[-n*2:]
    return [
        {"role": m["role"], "content": m["content"]}
        for m in recent if m.get("type") == "text"
    ]

# ===== ë©”ì¸ UI ì‹œì‘ =====
st.title("ğŸ’¬ Chat with Airtable")
st.write("ì—ì–´í…Œì´ë¸” ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ì§ˆë¬¸í•˜ê³  ì‘ë‹µë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# âœ… ë² ì´ìŠ¤ ì„ íƒ UI
bases = load_airtable_bases()
if not bases:
    st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì–´í…Œì´ë¸” ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ë² ì´ìŠ¤ê°€ 1ê°œë©´ ìë™ ì„ íƒ, ì•„ë‹ˆë©´ ì‚¬ìš©ìê°€ ì„ íƒ
if len(bases) == 1:
    selected_base = bases[0]
    st.success(f"âœ… 1ê°œ ë² ì´ìŠ¤ ìë™ ì„ íƒë¨: {selected_base['name']} ({selected_base['id']})")
else:
    base_options = {base["name"]: base for base in bases}
    selected_base_name = st.selectbox("ğŸ—‚ ì‚¬ìš©í•  ë² ì´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:", list(base_options.keys()))
    selected_base = base_options[selected_base_name]
    st.success(f"âœ… ì„ íƒëœ ë² ì´ìŠ¤: {selected_base['name']} ({selected_base['id']})")

# âœ… ì„ íƒí•œ ë² ì´ìŠ¤ì˜ í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
base_id = selected_base["id"]
base_name = selected_base["name"]
tables = get_all_tables_in_base(base_id)

if not tables:
    st.warning("ì„ íƒí•œ ë² ì´ìŠ¤ì— í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# í…Œì´ë¸” ì •ë³´ í‘œì‹œ
st.write(f"ğŸ“‹ í…Œì´ë¸” ëª©ë¡ ({len(tables)}ê°œ):")
for i, (table_name, table_id) in enumerate(tables):
    st.write(f"- {table_name} ({table_id})")

# âœ… ëª¨ë“  í…Œì´ë¸”ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
with st.expander("ğŸ“¦ í…Œì´ë¸” ë°ì´í„° ë¡œë”©", expanded=False):
    all_data = {}
    progress = st.progress(0)
    
    for i, (table_name, table_id) in enumerate(tables):
        st.write(f"ğŸ”„ í…Œì´ë¸” ë¡œë”© ì¤‘: {table_name}")
        records = get_airtable_data(base_id, table_id)
        if records:
            all_data[table_name] = records
        
        # ì§„í–‰ë¥  í‘œì‹œ
        progress.progress((i+1)/len(tables))
    
    st.success(f"âœ… ëª¨ë“  í…Œì´ë¸” ë°ì´í„° ë¡œë”© ì™„ë£Œ! ì´ {len(all_data)}ê°œ í…Œì´ë¸” ë¡œë“œë¨")

# âœ… ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° ì •ë¦¬ ê³¼ì •
with st.expander("ğŸ”„ ë°ì´í„°í”„ë ˆì„ ë³€í™˜", expanded=False):
    dataframes = {}
    
    for table_name, records in all_data.items():
        fields_only = [r.get("fields", {}) for r in records]
        df = pd.DataFrame(fields_only)
        
        if df.empty:
            st.warning(f"âš ï¸ {table_name}: ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
            
        # ì»¬ëŸ¼ ì •ì œ
        df.columns = [clean_column_name(c) for c in df.columns]
        
        # NaN-like ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
        for col in df.columns:
            df[col] = df[col].apply(
                lambda x: np.nan if isinstance(x, dict) and x.get("specialValue") == "NaN" else x
            )
        
        # ë³€ìˆ˜ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ì´ë¦„ ì •ì œ
        df_name = normalize_table_name(table_name)
        
        # ë³€ìˆ˜ ë“±ë¡
        dataframes[df_name] = df
        
        st.write(f"âœ… {df_name} ({table_name}): {df.shape[0]} rows, {df.shape[1]} columns")
    
    st.success("ğŸ‰ ëª¨ë“  í…Œì´ë¸”ì´ DataFrameìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

# âœ… ë‚ ì§œ í•„ë“œ ìë™ ì¸ì‹ ë° ë³€í™˜
with st.expander("ğŸ“… ë‚ ì§œ í•„ë“œ ìë™ ì¸ì‹", expanded=False):
    datetime_columns_summary = []
    
    for df_name, df in dataframes.items():
        converted_cols = []
        
        for col in df.columns:
            col_lower = col.lower()
            
            name_looks_like_date = any(keyword in col_lower for keyword in 
                                      ['date', 'created', 'expiry', 'changed', 'submitted'])
            value_looks_like_date = is_likely_date_column(df[col])
            
            if (name_looks_like_date or value_looks_like_date) and not should_exclude_column(col):
                try:
                    df[col] = pd.to_datetime(df[col], errors='coerce')
                    if pd.api.types.is_datetime64_any_dtype(df[col]):
                        converted_cols.append(col)
                        datetime_columns_summary.append((df_name, col))
                except Exception as e:
                    st.write(f"âš ï¸ [{df_name}] '{col}' ë³€í™˜ ì‹¤íŒ¨: {e}")
        
        if converted_cols:
            st.write(f"âœ… {df_name}: ë‚ ì§œ í•„ë“œ ë³€í™˜ ì™„ë£Œ â†’ {', '.join(converted_cols)}")
    
    # ë‚ ì§œ íŒŒìƒ í•„ë“œ ìë™ ìƒì„±
    st.write("ğŸ§© ë‚ ì§œ íŒŒìƒ í•„ë“œ ìƒì„± ì¤‘...")
    
    for df_name, df in dataframes.items():
        added = []
        
        for col in df.columns:
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                try:
                    df[f"{col}_year"] = df[col].dt.year
                    df[f"{col}_month"] = df[col].dt.month
                    df[f"{col}_quarter"] = df[col].dt.to_period("Q").astype(str)
                    added.append(col)
                except Exception as e:
                    st.write(f"âš ï¸ [{df_name}] {col} íŒŒìƒ í•„ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
        
        if added:
            st.write(f"âœ… {df_name}: íŒŒìƒ í•„ë“œ ìƒì„± ì™„ë£Œ â†’ {', '.join(added)}")
    
    st.success("ğŸ‰ ëª¨ë“  ë‚ ì§œ íŒŒìƒ í•„ë“œ ìƒì„± ì™„ë£Œ!")

# âœ… ë²”ì£¼í˜• í•„ë“œ(unique ê°’ ì ì€ í•„ë“œ) ì¶”ì¶œ
with st.expander("ğŸ§© ë²”ì£¼í˜• í•„ë“œ ì¶”ì¶œ", expanded=False):
    categorical_summary = {}
    
    for df_name, df in dataframes.items():
        cat_fields = {}
        
        for col in df.columns:
            if df[col].dtype in ["object", "category"]:
                # ë¦¬ìŠ¤íŠ¸ë‚˜ ë”•ì…”ë„ˆë¦¬ ë“¤ì–´ìˆëŠ” ì»¬ëŸ¼ì€ ì œì™¸
                sample_vals = df[col].dropna().head(10)
                if len(sample_vals) > 0 and sample_vals.apply(lambda x: isinstance(x, (list, dict))).any():
                    continue
                
                try:
                    unique_vals = df[col].dropna().unique()
                    if 0 < len(unique_vals) <= 10:
                        cat_fields[col] = list(map(str, unique_vals))
                except Exception as e:
                    st.write(f"âš ï¸ {df_name} / {col} unique ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        if cat_fields:
            categorical_summary[df_name] = cat_fields
            st.write(f"âœ… {df_name}: {len(cat_fields)}ê°œ í•„ë“œ ì¶”ì¶œë¨")
    
    st.success("âœ… ë²”ì£¼í˜• í•„ë“œ ì¶”ì¶œ ì™„ë£Œ!")

# âœ… ë©”íƒ€ë°ì´í„° ìš”ì•½ ìƒì„±
slim_meta_summary = {}

for df_name, df in dataframes.items():
    columns = {}
    for col in df.columns:
        col_data = df[col]
        col_entry = {}
        
        # datetime
        if pd.api.types.is_datetime64_any_dtype(col_data):
            col_entry["dtype"] = "datetime"
            derived = [f"{col}_year", f"{col}_quarter"]
            col_entry["derived"] = [d for d in derived if d in df.columns]
        
        # categorical
        elif col_data.dtype in ["object", "category"]:
            col_entry["dtype"] = "categorical"
            try:
                sample_vals = col_data.dropna().head(10)
                if len(sample_vals) > 0 and sample_vals.apply(lambda x: isinstance(x, (list, dict))).any():
                    continue
                unique_vals = col_data.dropna().unique()
                if 0 < len(unique_vals) <= 10:
                    col_entry["values"] = list(map(str, unique_vals[:10]))  # ìµœëŒ€ 10ê°œ í¬í•¨
            except:
                continue
        
        # numeric
        elif np.issubdtype(col_data.dtype, np.number):
            col_entry["dtype"] = "numeric"
        
        # í¬í•¨ ëŒ€ìƒë§Œ ê¸°ë¡
        if col_entry:
            columns[col] = col_entry
    
    if columns:
        slim_meta_summary[df_name] = {
            "record_count": len(df),
            "columns": columns
        }

# ë©”íƒ€ë°ì´í„° ìš”ì•½ ê°„ëµíˆ í‘œì‹œ
with st.expander("ğŸ“‹ ë©”íƒ€ë°ì´í„° ìš”ì•½", expanded=False):
    st.write(json.dumps({k: v for k, v in list(slim_meta_summary.items())[:1]}, indent=2))
    st.success("âœ… ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ!")

# âœ… ì§ˆë¬¸ ì…ë ¥ë€
user_question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

if user_question:
    # ì‚¬ìš©ì ì§ˆë¬¸ ì €ì¥
    st.session_state.chat_history.append({
        "role": "user", "content": user_question, "type": "text"
    })
    
    # GPT ì½”ë“œ ìƒì„± ìš”ì²­
    with st.spinner("ğŸ¤– GPTê°€ ì§ˆë¬¸ ë¶„ì„ ì¤‘..."):
        # ê° ë°ì´í„°í”„ë ˆì„ì˜ ì‹¤ì œ ëª¨ì–‘ ì •ë³´ ì¶”ê°€
        df_shapes = {}
        for df_name, df in dataframes.items():
            # ë°ì´í„°í”„ë ˆì„ì˜ ë³µì‚¬ë³¸ì„ ìƒì„±í•˜ì—¬ ë‚ ì§œ ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            sample_df = df.head(3).copy()
            
            # ë‚ ì§œ íƒ€ì… ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            for col in sample_df.columns:
                if pd.api.types.is_datetime64_any_dtype(sample_df[col]):
                    sample_df[col] = sample_df[col].astype(str)
            
            df_shapes[df_name] = {
                "rows": len(df),
                "columns": list(df.columns),
                "sample_data": sample_df.to_dict(orient='records') if not df.empty else {}
            }
            
        prompt = f"""
        ë‹¤ìŒì€ Airtableì—ì„œ ì¶”ì¶œí•œ í…Œì´ë¸” êµ¬ì¡° ìš”ì•½ì…ë‹ˆë‹¤:

        {json.dumps(slim_meta_summary, indent=2, ensure_ascii=False)}
        
        ë°ì´í„°í”„ë ˆì„ ì‹¤ì œ êµ¬ì¡° ì •ë³´:
        {json.dumps(df_shapes, indent=2, ensure_ascii=False)}

        ì‚¬ìš©ì ì§ˆë¬¸:
        {user_question}

        [ë¶„ì„ í™˜ê²½ ì•ˆë‚´]
        - ëª¨ë“  í…Œì´ë¸”ì€ ì´ë¯¸ pandas DataFrameìœ¼ë¡œ ë¡œë”©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
        - ê° í…Œì´ë¸”ì€ snake_caseë¡œ ì •ì œëœ ì´ë¦„ì˜ ë³€ìˆ˜ë¡œ ì¡´ì¬í•©ë‹ˆë‹¤. ì˜ˆì‹œ: "Client Database" â†’ client_database
        - ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê±°ë‚˜ ì§‘ê³„í•  ë•Œ ë°˜ë“œì‹œ ì´ DataFrameì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
        - ì‹¤í–‰ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ result ë³€ìˆ˜ì— ë‹´ê³ , print() ë“±ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
        - result ë³€ìˆ˜ëŠ” int, float, str, list, dict ë“± ê°„ë‹¨í•œ íƒ€ì…ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.
        - ì½”ë“œë¥¼ ì‘ì„±í•  ë•ŒëŠ” ìœ„ì— ì œê³µëœ ë°ì´í„°í”„ë ˆì„ ì‹¤ì œ êµ¬ì¡° ì •ë³´ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.
        - ì½”ë“œë§Œ ë°˜í™˜í•˜ê³ , ì„¤ëª…ì€ ìƒëµí•˜ì„¸ìš”.
        """

        messages = [
            {"role": "system", "content": "ë„ˆëŠ” Airtable ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": prompt}
        ]
        
        gpt_response = ask_gpt(messages)
        
        if gpt_response:
            code_str = extract_code_blocks(gpt_response)
            
            # ì½”ë“œ ì‹¤í–‰
            local_vars = {name: df for name, df in dataframes.items()}
            result = execute_code(code_str, local_vars)
            
            # ì½”ë“œ ì €ì¥
            st.session_state.chat_history.append({
                "type": "code", "content": code_str
            })
            
            if result["success"]:
                # ìì—°ì–´ í•´ì„ ìš”ì²­
                explain_prompt = f"""
                ì‚¬ìš©ìì˜ ì§ˆë¬¸:
                {user_question}

                ì½”ë“œ ì‹¤í–‰ ê²°ê³¼:
                {result["result"]}

                [ì§€ì¹¨]
                - ê²°ê³¼ë¥¼ ì§ì ‘ì ìœ¼ë¡œ í•´ì„í•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´ì£¼ì„¸ìš”.
                - ì§ˆë¬¸ ë‚´ìš©ì„ ë°˜ë³µí•˜ê±°ë‚˜ ìš”ì•½í•˜ì§€ ë§ê³ , ê²°ê³¼ ìì²´ì— ì´ˆì ì„ ë§ì¶° í•´ì„í•˜ì„¸ìš”.
                """
                
                explain_messages = [
                    {"role": "system", "content": "ì¹œì ˆí•œ ë¶„ì„ê°€"},
                    {"role": "user", "content": explain_prompt}
                ]
                
                explain_response = ask_gpt(explain_messages)
                
                if explain_response:
                    explain_response = sanitize_colon_spacing(explain_response)
                    st.session_state.chat_history.append({
                        "role": "assistant", "content": explain_response, "type": "text"
                    })
                else:
                    st.warning("GPT ì„¤ëª… ìƒì„± ì‹¤íŒ¨")
            else:
                error_msg = result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                st.error("ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ")
                
                # ì˜¤ë¥˜ ë©”ì‹œì§€ì—ì„œ ë” ì¹œì ˆí•œ í˜•íƒœë¡œ ë³€í™˜
                simplified_error = re.sub(r'File ".*?", line \d+, in .*?\n', '', error_msg)
                simplified_error = re.sub(r'File "<string>", line \d+, in <module>\n', '', simplified_error)
                
                # ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•œ ì˜¤ë¥˜ ì„¤ëª… ìƒì„± ìš”ì²­
                error_explain_prompt = f"""
                ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_question}
                ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {simplified_error}
                
                ì´ ì˜¤ë¥˜ì˜ ì›ì¸ê³¼ í•´ê²° ë°©ë²•ì„ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                """
                error_messages = [{"role": "system", "content": "ì¹œì ˆí•œ ë°ì´í„° ì „ë¬¸ê°€"}]
                error_messages.append({"role": "user", "content": error_explain_prompt})
                error_response = ask_gpt(error_messages)
                
                if error_response:
                    st.session_state.chat_history.append({
                        "role": "assistant", "content": error_response, "type": "text"
                    })
                else:
                    st.session_state.chat_history.append({
                        "role": "assistant", "content": f"ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {simplified_error}", "type": "text"
                    })
        else:
            st.warning("GPT ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

# UIì— ì±„íŒ… ê¸°ë¡ í‘œì‹œ
render_chat_history()

# âœ… ì•± ì†Œê°œ ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ¤– Chat with Airtable")
    st.markdown("""
    ## ì‚¬ìš© ë°©ë²•
    1. ì—ì–´í…Œì´ë¸” ë² ì´ìŠ¤ê°€ ìë™ìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤.
    2. ë°ì´í„°ëŠ” pandas DataFrameìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
    3. ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ GPTê°€ ì½”ë“œë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    4. ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    ## ë°ì´í„°í”„ë ˆì„ ì •ë³´
    """)
    
    for df_name, df in dataframes.items():
        st.markdown(f"**{df_name}**: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
